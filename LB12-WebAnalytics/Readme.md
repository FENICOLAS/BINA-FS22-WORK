# LB12 - Web Analytics README
###### Last update: 08/4/22 dbe
</br>

![MSc-WI_BINA-FS22_LB12_Web Analytics-CHAPTERS](https://user-images.githubusercontent.com/52699611/162425861-206be02d-edfd-49d0-8e2e-7bfbf51d12a2.png)


## A) Web Analytics

> *"The importance of a Web page is an inherently sub jective matter, which depends on the
readers interests, knowledge and attitudes. But there is still much that can be said ob jectively
about the relative importance of Web pages."*  
> *Sergey Brin and Larry Page, "The PageRank Citation Ranking: Bringing Order to the Web", 1998*
 
* [The Academic Paper That Started Google](https://www.sciencedirect.com/science/article/pii/S016975529800110X).  In 1995, Larry Page met Sergey Brin. At the time, Page and Brin were Ph.D students at Stanford University. The two began collaborating on a research project nicknamed “BackRub” with the goal of ranking web pages into a measure of importance by converting their backlink data. Without knowing it at the time, Page and Brin developed the [PageRank algorithm](http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf) that became the original Google Search algorithm.  
* xxxx
* xxxx


</br> 

## B) Tools and Examples

![image](https://user-images.githubusercontent.com/52699611/162431175-6ced3fef-3746-4be4-a981-7685eb6b3210.png)


* [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) - A Python library for pulling data out of HTML and XML files. See in the Blog [How open source software is fighting COVID-19](https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19) the *DXY-COVID-19-Crawler* of BlankerL that was created in January 2020 and is one of the earliest responses from the open source community to COVID-19. When the virus was spreading primarily in China, the Chinese medical community was using a site called DXY.cn to report and track cases. To make the information more readily available and usable by others, GitHub user BlankerL wrote a web crawler to systematically collect data from the DXY.cn site and make it available via an API and data warehouse. 

* [Scrapy](https://scrapy.org/) - An Open Source Framework for Crawling Websites and Extracting Structured Data (Scraping)  

* [Webscraper.io](https://webscraper.io/) - A free Chrome Extension. See the [Video Tutorial](https://youtu.be/n7fob_XVsbY) on using the webscraper to scrape a simple ecommerce site
 
* [Selenium](https://www.selenium.dev/) - Web Automation Testing through Selenium and Python

* [Rvest](https://rvest.tidyverse.org/) - Easily Harvest (Scrape) Web Pages. See the[ Datacamp](https://www.datacamp.com/community/tutorials/r-web-scraping-rvest) Tutorial

* [Disco](https://fluxicon.com/disco/) from Fluxicon -  See the [Customer Journey Analysis](https://fluxicon.com/blog/2021/02/process-mining-cafe-daisy/) Show Case with Daisy Wain from GOV.UK at the Fluxicon Process Mining Cafe 03 
